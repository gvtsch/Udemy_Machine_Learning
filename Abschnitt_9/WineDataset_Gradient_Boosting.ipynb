{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\r\n",
    "np.random.seed(42)\r\n",
    "import pandas as pd\r\n",
    "from sklearn.datasets import load_wine\r\n",
    "from sklearn.tree import DecisionTreeClassifier\r\n",
    "from sklearn.ensemble import RandomForestClassifier\r\n",
    "from sklearn.model_selection import GridSearchCV\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_wine()\r\n",
    "x, y = dataset.data, dataset.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>alcohol</th>\n      <th>malic_acid</th>\n      <th>ash</th>\n      <th>alcalinity_of_ash</th>\n      <th>magnesium</th>\n      <th>total_phenols</th>\n      <th>flavanoids</th>\n      <th>nonflavanoid_phenols</th>\n      <th>proanthocyanins</th>\n      <th>color_intensity</th>\n      <th>hue</th>\n      <th>od280/od315_of_diluted_wines</th>\n      <th>proline</th>\n      <th>y</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>14.23</td>\n      <td>1.71</td>\n      <td>2.43</td>\n      <td>15.6</td>\n      <td>127.0</td>\n      <td>2.80</td>\n      <td>3.06</td>\n      <td>0.28</td>\n      <td>2.29</td>\n      <td>5.64</td>\n      <td>1.04</td>\n      <td>3.92</td>\n      <td>1065.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>13.20</td>\n      <td>1.78</td>\n      <td>2.14</td>\n      <td>11.2</td>\n      <td>100.0</td>\n      <td>2.65</td>\n      <td>2.76</td>\n      <td>0.26</td>\n      <td>1.28</td>\n      <td>4.38</td>\n      <td>1.05</td>\n      <td>3.40</td>\n      <td>1050.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>13.16</td>\n      <td>2.36</td>\n      <td>2.67</td>\n      <td>18.6</td>\n      <td>101.0</td>\n      <td>2.80</td>\n      <td>3.24</td>\n      <td>0.30</td>\n      <td>2.81</td>\n      <td>5.68</td>\n      <td>1.03</td>\n      <td>3.17</td>\n      <td>1185.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>14.37</td>\n      <td>1.95</td>\n      <td>2.50</td>\n      <td>16.8</td>\n      <td>113.0</td>\n      <td>3.85</td>\n      <td>3.49</td>\n      <td>0.24</td>\n      <td>2.18</td>\n      <td>7.80</td>\n      <td>0.86</td>\n      <td>3.45</td>\n      <td>1480.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>13.24</td>\n      <td>2.59</td>\n      <td>2.87</td>\n      <td>21.0</td>\n      <td>118.0</td>\n      <td>2.80</td>\n      <td>2.69</td>\n      <td>0.39</td>\n      <td>1.82</td>\n      <td>4.32</td>\n      <td>1.04</td>\n      <td>2.93</td>\n      <td>735.0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "   alcohol  malic_acid   ash  alcalinity_of_ash  magnesium  total_phenols  \\\n0    14.23        1.71  2.43               15.6      127.0           2.80   \n1    13.20        1.78  2.14               11.2      100.0           2.65   \n2    13.16        2.36  2.67               18.6      101.0           2.80   \n3    14.37        1.95  2.50               16.8      113.0           3.85   \n4    13.24        2.59  2.87               21.0      118.0           2.80   \n\n   flavanoids  nonflavanoid_phenols  proanthocyanins  color_intensity   hue  \\\n0        3.06                  0.28             2.29             5.64  1.04   \n1        2.76                  0.26             1.28             4.38  1.05   \n2        3.24                  0.30             2.81             5.68  1.03   \n3        3.49                  0.24             2.18             7.80  0.86   \n4        2.69                  0.39             1.82             4.32  1.04   \n\n   od280/od315_of_diluted_wines  proline  y  \n0                          3.92   1065.0  0  \n1                          3.40   1050.0  0  \n2                          3.17   1185.0  0  \n3                          3.45   1480.0  0  \n4                          2.93    735.0  0  "
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(x, columns = dataset.feature_names)\r\n",
    "df[\"y\"] = y\r\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cart Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "GridSearchCV(cv=10, estimator=DecisionTreeClassifier(), n_jobs=-1,\n             param_grid={'criterion': ['gini', 'entropy'],\n                         'max_depth': [None, 2, 4, 8, 10]})"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {\r\n",
    "    'criterion': ['gini', 'entropy'],\r\n",
    "    'max_depth': [None, 2, 4, 8, 10]\r\n",
    "}\r\n",
    "\r\n",
    "clf = DecisionTreeClassifier()\r\n",
    "grid_cv = GridSearchCV(clf, parameters, cv = 10, n_jobs = -1)\r\n",
    "grid_cv.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters of best model: {'criterion': 'gini', 'max_depth': None}\n",
      "Score of best model: 0.9448717948717948\n"
     ]
    }
   ],
   "source": [
    "print(f\"Parameters of best model: {grid_cv.best_params_}\")\r\n",
    "print(f\"Score of best model: {grid_cv.best_score_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CART Classifier Train best model\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9444444444444444\n"
     ]
    }
   ],
   "source": [
    "clf = DecisionTreeClassifier(\r\n",
    "    criterion='gini', \r\n",
    "    max_depth=4)\r\n",
    "clf.fit(x_train, y_train)\r\n",
    "score = clf.score(x_test, y_test)\r\n",
    "print(f\"Accuracy: {score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForrest Classifier: Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "GridSearchCV(cv=10, estimator=RandomForestClassifier(), n_jobs=-1,\n             param_grid={'criterion': ['gini', 'entropy'],\n                         'max_depth': [None, 2, 4, 8, 10],\n                         'n_estimators': [10, 20, 40, 80, 160]})"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {\r\n",
    "    'n_estimators': [10, 20, 40, 80, 160],\r\n",
    "    'criterion': ['gini', 'entropy'],\r\n",
    "    'max_depth': [None, 2, 4, 8, 10]\r\n",
    "}\r\n",
    "np.random.seed(42)\r\n",
    "\r\n",
    "clf = RandomForestClassifier()\r\n",
    "grid_cv = GridSearchCV(clf, parameters, cv = 10, n_jobs = -1)\r\n",
    "grid_cv.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters of best model: {'criterion': 'entropy', 'max_depth': None, 'n_estimators': 20}\n",
      "Score of best model: 0.9839743589743589\n"
     ]
    }
   ],
   "source": [
    "print(f\"Parameters of best model: {grid_cv.best_params_}\")\r\n",
    "print(f\"Score of best model: {grid_cv.best_score_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Train\r\n",
    "clf = RandomForestClassifier(n_estimators = 20, criterion='gini', max_depth = 4)\r\n",
    "clf.fit(x_train, y_train)\r\n",
    "print(f\"Accuracy: {clf.score(x_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Tools\\Python-Extra-PyPI\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [0.91282051 0.91282051 0.91282051 0.91987179 0.93525641 0.94358974\n",
      " 0.91282051 0.90448718 0.91282051 0.90448718 0.91282051 0.91282051\n",
      " 0.90448718 0.90448718 0.91282051        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.91153846 0.91987179 0.91987179 0.91346154 0.92115385 0.92884615\n",
      " 0.89679487 0.92884615 0.91987179 0.92884615 0.90384615 0.92051282\n",
      " 0.91987179 0.90320513 0.93589744        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan]\n",
      "  category=UserWarning\n"
     ]
    },
    {
     "data": {
      "text/plain": "GridSearchCV(cv=10, estimator=GradientBoostingClassifier(), n_jobs=-1,\n             param_grid={'criterion': ['mse', 'mae'],\n                         'loss': ['deviance', 'exponential'],\n                         'max_depth': [None, 2, 4, 8, 10],\n                         'n_estimators': [10, 20, 40]})"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {\r\n",
    "    'loss': ['deviance', 'exponential'],\r\n",
    "    'n_estimators': [10, 20, 40],\r\n",
    "    'criterion': ['mse', 'mae'],\r\n",
    "    'max_depth': [None, 2, 4, 8, 10]\r\n",
    "}\r\n",
    "np.random.seed(42)\r\n",
    "\r\n",
    "clf = GradientBoostingClassifier()\r\n",
    "grid_cv = GridSearchCV(clf, parameters, cv = 10, n_jobs = -1)\r\n",
    "grid_cv.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters of best model: {'criterion': 'mse', 'loss': 'deviance', 'max_depth': 2, 'n_estimators': 40}\n",
      "Score of best model: 0.9435897435897436\n"
     ]
    }
   ],
   "source": [
    "print(f\"Parameters of best model: {grid_cv.best_params_}\")\r\n",
    "print(f\"Score of best model: {grid_cv.best_score_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9629629629629629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Tools\\Python-Extra-PyPI\\site-packages\\sklearn\\ensemble\\_gb.py:1122: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). Use criterion='friedman_mse' or 'mse' instead, as trees should use a least-square criterion in Gradient Boosting.\n",
      "  \"Boosting.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Train\r\n",
    "clf = GradientBoostingClassifier(loss = 'deviance', n_estimators = 10, criterion='mae', max_depth = 8)\r\n",
    "clf.fit(x_train, y_train)\r\n",
    "print(f\"Accuracy: {clf.score(x_test, y_test)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.2 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "eb5e4990910e14dd45c435c2968b5a5f5ce800b4f8a2bb72e1f77e313f787063"
    }
   },
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}